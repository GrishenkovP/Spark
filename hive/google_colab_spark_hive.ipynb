{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Save DataFrame to Hive Table"
      ],
      "metadata": {
        "id": "xnyxs-D6U8hT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fcxqg8Wf_zSK"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "wEaoXZBMAhIw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init('spark-3.3.1-bin-hadoop3')"
      ],
      "metadata": {
        "id": "4RCiOWA7Ajnv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType"
      ],
      "metadata": {
        "id": "zJq-JqkMBQWo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master('local[*]').enableHiveSupport().appName(\"SparkTest\").getOrCreate()"
      ],
      "metadata": {
        "id": "-aHyZXlTAoDf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
        "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
        "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
        "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"Product\",StringType(),True), \\\n",
        "    StructField(\"Amount\",IntegerType(),True), \\\n",
        "    StructField(\"Country\",StringType(),True)\n",
        "  ])\n",
        " \n",
        "df = spark.createDataFrame(data=data,schema=schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5JsRA7nAlm_",
        "outputId": "a7253fb1-bfe1-4dcc-f944-5d27015b79d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Amount: integer (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+-------+------+-------+\n",
            "|Product|Amount|Country|\n",
            "+-------+------+-------+\n",
            "|Banana |1000  |USA    |\n",
            "|Carrots|1500  |USA    |\n",
            "|Beans  |1600  |USA    |\n",
            "|Orange |2000  |USA    |\n",
            "|Orange |2000  |USA    |\n",
            "|Banana |400   |China  |\n",
            "|Carrots|1200  |China  |\n",
            "|Beans  |1500  |China  |\n",
            "|Orange |4000  |China  |\n",
            "|Banana |2000  |Canada |\n",
            "|Carrots|2000  |Canada |\n",
            "|Beans  |2000  |Mexico |\n",
            "+-------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"CREATE DATABASE IF NOT EXISTS test_db\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv7E1omAUboB",
        "outputId": "6cbc90cc-b8ee-41d8-ddc4-4a53c097f54f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SHOW DATABASES\"\"\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJW-fxCLUeBZ",
        "outputId": "4ad1dc86-184b-416c-f2c9-f385df948c72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "|  test_db|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    df.write\n",
        "    .partitionBy(\"Product\")\n",
        "    .mode(\"overwrite\")\n",
        "    .saveAsTable(\"test_db.sales_hive\")\n",
        " \n",
        ")"
      ],
      "metadata": {
        "id": "mtiDElUCNyJk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SHOW TABLES IN test_db\"\"\").show(100, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99c4MLvofLge",
        "outputId": "b93b11aa-9752-4c3b-db12-5744ca6d892d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----------+\n",
            "|namespace|tableName |isTemporary|\n",
            "+---------+----------+-----------+\n",
            "|test_db  |sales_hive|false      |\n",
            "+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"DESCRIBE FORMATTED test_db.sales_hive\"\"\").show(100, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqICaKVxfOnO",
        "outputId": "1a8acc77-075e-477c-e909-ab16f0ebe49c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|col_name                    |data_type                                                     |comment|\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "|Amount                      |int                                                           |null   |\n",
            "|Country                     |string                                                        |null   |\n",
            "|Product                     |string                                                        |null   |\n",
            "|# Partition Information     |                                                              |       |\n",
            "|# col_name                  |data_type                                                     |comment|\n",
            "|Product                     |string                                                        |null   |\n",
            "|                            |                                                              |       |\n",
            "|# Detailed Table Information|                                                              |       |\n",
            "|Database                    |test_db                                                       |       |\n",
            "|Table                       |sales_hive                                                    |       |\n",
            "|Owner                       |root                                                          |       |\n",
            "|Created Time                |Fri Jan 06 14:37:24 UTC 2023                                  |       |\n",
            "|Last Access                 |UNKNOWN                                                       |       |\n",
            "|Created By                  |Spark 3.3.1                                                   |       |\n",
            "|Type                        |MANAGED                                                       |       |\n",
            "|Provider                    |parquet                                                       |       |\n",
            "|Location                    |file:/content/spark-warehouse/test_db.db/sales_hive           |       |\n",
            "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
            "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
            "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
            "|Partition Provider          |Catalog                                                       |       |\n",
            "+----------------------------+--------------------------------------------------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT db.* FROM test_db.sales_hive as db\"\"\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvxvAcgyUli5",
        "outputId": "ade82d15-ecee-4736-e758-82c83edfb29f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-------+\n",
            "|Amount|Country|Product|\n",
            "+------+-------+-------+\n",
            "|  2000|    USA| Orange|\n",
            "|  2000|    USA| Orange|\n",
            "|  2000| Canada| Banana|\n",
            "|  1500|  China|  Beans|\n",
            "|  2000| Mexico|  Beans|\n",
            "|  1200|  China|Carrots|\n",
            "|  2000| Canada|Carrots|\n",
            "|  4000|  China| Orange|\n",
            "|  1000|    USA| Banana|\n",
            "|   400|  China| Banana|\n",
            "+------+-------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
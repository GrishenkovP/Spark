{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH9NLWD13EjB"
      },
      "source": [
        "# Install the dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Cokct83h5R"
      },
      "source": [
        "# Set the environment variables for running PySpark in the collaboration environmentimport os\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaccJdNb4hol"
      },
      "source": [
        "# Run the local session to test the installation\n",
        "import findspark\n",
        "findspark.init('spark-3.0.1-bin-hadoop3.2')\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEYQkq_9ix9s"
      },
      "source": [
        "# Define schema for out data\r\n",
        "schema_sales = \"date STRING, region STRING, manager STRING, product STRING, amount INT\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AK9VVVGlTzi"
      },
      "source": [
        "# Connect Google Drive!!! (files section)\r\n",
        "data = spark.read.csv(\"/content/drive/MyDrive/db/sales.csv\", schema = schema_sales, header = True, sep=\";\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCib1MPhHugv"
      },
      "source": [
        "# Change column type from string to date (for example, '10.01.2020' - '2020-01-10')\r\n",
        "from datetime import datetime\r\n",
        "from pyspark.sql.functions import col, udf\r\n",
        "from pyspark.sql.types import *\r\n",
        "udf_date = udf(lambda x:datetime.strptime(x, \"%d.%m.%Y\"),DateType())\r\n",
        "df = data.withColumn('date',udf_date(col('date')))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkLYC51yQd_r",
        "outputId": "60c45242-7659-4a4a-ffbc-9a6e7732e4b2"
      },
      "source": [
        "df.show(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------+-------+-------+------+\n",
            "|      date|region|manager|product|amount|\n",
            "+----------+------+-------+-------+------+\n",
            "|2020-01-01| north|   Mark|  metal|  3899|\n",
            "|2020-01-02| south|  David|   wood|  2283|\n",
            "|2020-01-03|  west|   John|  metal|  4812|\n",
            "|2020-01-04|  east|William|   wood|  5452|\n",
            "|2020-01-05| north|   Mark|  metal|  9855|\n",
            "|2020-01-06| south|  David|   wood|  5040|\n",
            "|2020-01-07|  west|   John|  metal|  4801|\n",
            "|2020-01-08|  east|William|   wood|  5752|\n",
            "|2020-01-09| north|   Mark|  metal|  8721|\n",
            "|2020-01-10| south|  David|   wood|  8020|\n",
            "+----------+------+-------+-------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67YgJyIvYVjw",
        "outputId": "13bf8d64-5ebe-4310-b8f1-ef80e8652d85"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- manager: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2UnREz8d6Qm"
      },
      "source": [
        "df.createOrReplaceTempView(\"tbl\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUan-1LVsqoP",
        "outputId": "2deeed34-b855-4798-d2f2-cfc5cfb96003"
      },
      "source": [
        "# Query SQL. Select all records where region = north and product = metal\r\n",
        "spark.sql(\"\"\"SELECT *\r\n",
        "FROM tbl \r\n",
        "WHERE (product = 'metal' AND region = 'north')\r\n",
        "ORDER BY amount DESC\"\"\").show(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------+-------+-------+------+\n",
            "|      date|region|manager|product|amount|\n",
            "+----------+------+-------+-------+------+\n",
            "|2020-01-05| north|   Mark|  metal|  9855|\n",
            "|2020-02-06| north|   Mark|  metal|  9382|\n",
            "|2020-02-26| north|   Mark|  metal|  8763|\n",
            "|2020-01-09| north|   Mark|  metal|  8721|\n",
            "|2020-02-02| north|   Mark|  metal|  8589|\n",
            "|2020-01-17| north|   Mark|  metal|  6467|\n",
            "|2020-02-22| north|   Mark|  metal|  6352|\n",
            "|2020-01-25| north|   Mark|  metal|  5163|\n",
            "|2020-01-21| north|   Mark|  metal|  4060|\n",
            "|2020-01-01| north|   Mark|  metal|  3899|\n",
            "+----------+------+-------+-------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcnO_qmJtIk-",
        "outputId": "5ad8ff4b-cbe8-4d2d-afa7-2e997f9baf3a"
      },
      "source": [
        "# Query SQL. CASE\r\n",
        "spark.sql(\"\"\"SELECT date, \r\n",
        "CASE \r\n",
        "WHEN Month(date)=1 THEN 'January'\r\n",
        "WHEN Month(date)=2 THEN 'February'\r\n",
        "ELSE 'no'\r\n",
        "END as Month\r\n",
        "FROM tbl\"\"\").show(10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+\n",
            "|      date|  Month|\n",
            "+----------+-------+\n",
            "|2020-01-01|January|\n",
            "|2020-01-02|January|\n",
            "|2020-01-03|January|\n",
            "|2020-01-04|January|\n",
            "|2020-01-05|January|\n",
            "|2020-01-06|January|\n",
            "|2020-01-07|January|\n",
            "|2020-01-08|January|\n",
            "|2020-01-09|January|\n",
            "|2020-01-10|January|\n",
            "+----------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFItdphYyLMV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
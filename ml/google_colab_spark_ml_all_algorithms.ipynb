{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_colab_spark_ml_all_algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark. Алгоритмы машинного обучения"
      ],
      "metadata": {
        "id": "rp5PQnP2tcOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полный список алгоритмов можно посмотреть в официальной документации https://spark.apache.org/docs/latest/ml-classification-regression.html"
      ],
      "metadata": {
        "id": "ibUvcAsbHzRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgW3EGNhsh3h"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pyspark\n",
        "# from pyspark.sql import SparkSession\n",
        "# # В качестве примера используется порт по умолчанию (local)\n",
        "# conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
        "# # Развертывание среды Spark с указанными настройками\n",
        "# sc = pyspark.SparkContext(conf=conf)\n",
        "# # Запуск Spark-сессии\n",
        "# spark = SparkSession(sc)"
      ],
      "metadata": {
        "id": "xFrBm4ysPZw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()"
      ],
      "metadata": {
        "id": "gKC0E1fTthzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "0EUrkvLQttjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data[:,:4]\n",
        "y = iris.target\n",
        "df = pd.DataFrame(X,columns=iris.feature_names)\n",
        "df['target'] = y\n",
        "df.columns = ['sepal_length','sepal_width','petal_length','petal_width','target']\n",
        "df['name_iris'] = df['target'].apply(lambda _:iris.target_names[_])"
      ],
      "metadata": {
        "id": "dpMsW1kwtySp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print('---------------------------------------')\n",
        "print(df.info())\n",
        "print('---------------------------------------')\n",
        "print(df.name_iris.value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqK6HOU3uKjY",
        "outputId": "16698b76-1b71-462e-8f2f-6b0328d7979f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width  target name_iris\n",
            "0           5.1          3.5           1.4          0.2       0    setosa\n",
            "1           4.9          3.0           1.4          0.2       0    setosa\n",
            "2           4.7          3.2           1.3          0.2       0    setosa\n",
            "3           4.6          3.1           1.5          0.2       0    setosa\n",
            "4           5.0          3.6           1.4          0.2       0    setosa\n",
            "---------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   target        150 non-null    int64  \n",
            " 5   name_iris     150 non-null    object \n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 7.2+ KB\n",
            "None\n",
            "---------------------------------------\n",
            "virginica     0.333333\n",
            "versicolor    0.333333\n",
            "setosa        0.333333\n",
            "Name: name_iris, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('data.csv', index=False)"
      ],
      "metadata": {
        "id": "uxku7MikuM5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('data.csv',inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "dG3jz9n6uO2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6nNjYlJuSz4",
        "outputId": "aaf21685-cd49-455b-cfb1-7304be905782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+------+---------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|target|name_iris|\n",
            "+------------+-----------+------------+-----------+------+---------+\n",
            "|         5.1|        3.5|         1.4|        0.2|     0|   setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2|     0|   setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2|     0|   setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2|     0|   setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2|     0|   setosa|\n",
            "+------------+-----------+------------+-----------+------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MNhGqkauU74",
        "outputId": "ad727aee-6e66-4379-d5c2-eaeb3a5a432f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- name_iris: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "QynEHu3guiv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_assembler = VectorAssembler(inputCols=['sepal_length','sepal_width','petal_length','petal_width'],outputCol='features')"
      ],
      "metadata": {
        "id": "5xOMW2kwuj23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_assembler.transform(df)"
      ],
      "metadata": {
        "id": "6baeXjiBulkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(['features','target']).show(5,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3KMn9TXunkY",
        "outputId": "70f8630a-b324-4aae-eb1b-5151e4bc4de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------+\n",
            "|features         |target|\n",
            "+-----------------+------+\n",
            "|[5.1,3.5,1.4,0.2]|0     |\n",
            "|[4.9,3.0,1.4,0.2]|0     |\n",
            "|[4.7,3.2,1.3,0.2]|0     |\n",
            "|[4.6,3.1,1.5,0.2]|0     |\n",
            "|[5.0,3.6,1.4,0.2]|0     |\n",
            "+-----------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = df.select(['features','target'])"
      ],
      "metadata": {
        "id": "aPLovVOiuq3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df_2_class = model_df.filter(model_df.target.isin(0,1))"
      ],
      "metadata": {
        "id": "gAyfShVsxcK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df, test_df = model_df.randomSplit([0.75,0.25])"
      ],
      "metadata": {
        "id": "ldkrFQKMuux4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df_2_class, test_df_2_class = model_df_2_class.randomSplit([0.75,0.25])"
      ],
      "metadata": {
        "id": "65cduQjRyPPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBT-алгоритм"
      ],
      "metadata": {
        "id": "oyW4AHegvSuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GBT (Gradient Boost Tree) – это алгоритм машинного обучения, использующийся для задач классификации и регрессии, который строит модель предсказания величины в форме ансамбля слабых предсказывающих моделей, в частности деревьев решений."
      ],
      "metadata": {
        "id": "WRZmP73uvnu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "cU7pir8lvVIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbt = GBTClassifier(labelCol='target',featuresCol='features', maxDepth=10)"
      ],
      "metadata": {
        "id": "dLTCzOz-vtP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gbt = gbt.fit(training_df_2_class)"
      ],
      "metadata": {
        "id": "EHWJz-NQv5JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_gbt = model_gbt.transform(test_df_2_class)"
      ],
      "metadata": {
        "id": "yjZ7DSyVyebm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_gbt.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsI9ceiZzLQn",
        "outputId": "2a974524-4b94-4242-c841-4957abcea147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------+--------------------+--------------------+----------+\n",
            "|         features|target|       rawPrediction|         probability|prediction|\n",
            "+-----------------+------+--------------------+--------------------+----------+\n",
            "|[4.4,2.9,1.4,0.2]|     0|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
            "|[4.4,3.2,1.3,0.2]|     0|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
            "|[4.6,3.1,1.5,0.2]|     0|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
            "|[4.6,3.4,1.4,0.3]|     0|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
            "|[4.6,3.6,1.0,0.2]|     0|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
            "+-----------------+------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "                                            labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_gbt = evaluator.evaluate(predictions_gbt)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy_gbt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tdLRobnynp1",
        "outputId": "bc27caf1-e3c6-444e-b2c9-d4a370d30ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Алгоритм One-vs-Rest"
      ],
      "metadata": {
        "id": "FhnojHEXzue1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм «Один против всех» (One vs all или One vs Rest) – это модель, которая предоставляет путь решения бинарной классификации из нескольких возможных решений. В течение обучения модель проходит через последовательность бинарных классификаторов (по одному бинарному классификатору для каждого возможного выхода), тренируя каждый их них отвечать на отдельный классификационный вопрос."
      ],
      "metadata": {
        "id": "7GugEYS7z40d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression, OneVsRest"
      ],
      "metadata": {
        "id": "2hpR64xFz1Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)"
      ],
      "metadata": {
        "id": "MMcAdZnE0Kxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ovr = OneVsRest(classifier=lr,labelCol='target',featuresCol='features')"
      ],
      "metadata": {
        "id": "0htbaM4u0N36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ovr = ovr.fit(training_df)\n",
        "predictions_ovr = model_ovr.transform(test_df)"
      ],
      "metadata": {
        "id": "-QF8rEb70REK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "                                            labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_ovr = evaluator.evaluate(predictions_ovr)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy_ovr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13wmrxou0lht",
        "outputId": "ea183067-a3d4-4122-a905-a6bc894dd66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Алгоритм случайного леса"
      ],
      "metadata": {
        "id": "I3RikVOY1a79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Случайный лес (random forest) – это алгоритм машинного обучения, который заключается в использовании ансамбля (совокупности) деревьев решений (decision trees). Ключевая идея заключается в том, что качество классификации в случайном лесу повышается за счет большого количества ансамблей деревьев решений. Классификация проводится путем голосования деревьев, где каждое дерево относит классифицируемый объект к одному из классов. Побеждает тот класс, за который проголосовало наибольшее число деревьев. Оптимальное число деревьев подбирается таким образом, чтобы минимизировать ошибку классификации на тестовой выборке."
      ],
      "metadata": {
        "id": "Ny1LNbo11fs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import RandomForestRegressor"
      ],
      "metadata": {
        "id": "yXPdKDTK1evd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol='target', numTrees=10)"
      ],
      "metadata": {
        "id": "7FXcISEc1rhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf = rf.fit(training_df)\n",
        "predictions_rf = model_rf.transform(test_df)"
      ],
      "metadata": {
        "id": "u7A2OPcD17E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(\n",
        "                                labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse_rf = evaluator.evaluate(predictions_rf)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8_mjoqP2KAc",
        "outputId": "7ba0527f-47e8-46f9-cdf5-081ba68e3550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 0.177658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метод опорных векторов"
      ],
      "metadata": {
        "id": "4TZnUZIX2cvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод опорных векторов (support vector machine, SVM) — алгоритм классификации, в основе которого лежит определяемая разделяющая гиперплоскость (линия, прямая, многомерные плоскости). Другими словами, при заданных тренировочных данных алгоритм находит такую гиперплоскость, которая разделяет данные, принадлежащие разным классам, самым оптимальным способом. В двухмерном пространстве гиперплоскостью служит прямая линия."
      ],
      "metadata": {
        "id": "TkaHQ1uc2hq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "VluA3G6-2hSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc = LinearSVC(labelCol=\"target\", regParam=0.1)\n",
        "model_lsvc = lsvc.fit(training_df_2_class)"
      ],
      "metadata": {
        "id": "FO54-WB228Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coefficients:\", model_lsvc.coefficients)\n",
        "print(\"Intercept:\", model_lsvc.intercept)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZSNVQqI3Po7",
        "outputId": "54244cad-11ab-4f1f-d706-2ac628cab7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.2825404213109134,-0.811639491578646,0.3446898161477943,0.9344901652684454]\n",
            "Intercept: -0.6841886400260185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_lsvc = model_lsvc.transform(test_df_2_class)"
      ],
      "metadata": {
        "id": "M3ZUx33a3qFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=\"target\")\n",
        "accuracy_lsvc = evaluator.evaluate(predictions_lsvc)\n",
        "print(f\"Test Error =\", (1.0 - accuracy_lsvc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do_VTRBZ3Ywq",
        "outputId": "7f4801d4-4aca-4b35-b1dd-403a52283db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Наивный байесовский классификатор"
      ],
      "metadata": {
        "id": "fu9n800J4R_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наивный байесовский классификатор (Naive Bayes) — это алгоритм машинного обучения, предназначенный для многоклассовой классификации данных с независимыми признаками. За один проход вычисляется условная вероятность каждого признака, затем применяется теорема Байеса для нахождения распределения вероятности наблюдений."
      ],
      "metadata": {
        "id": "Ar6_HSY74TkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полиномиальный байесовский классификатор\n",
        "Бернуллевский байесовский классификатор\n",
        "Дополняющий байесовский классификатор\n",
        "Гауссовский байесовский классификатор"
      ],
      "metadata": {
        "id": "0PnHkA6F4mXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(modelType=\"multinomial\",labelCol='target')\n",
        "model_nb = nb.fit(training_df)"
      ],
      "metadata": {
        "id": "hXyZpu0U4TPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_nb = model_nb.transform(test_df)\n",
        "predictions_nb.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zhd1mHZ5L1B",
        "outputId": "c0548a57-c2b5-4808-8964-4345e239beb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------+--------------------+--------------------+----------+\n",
            "|         features|target|       rawPrediction|         probability|prediction|\n",
            "+-----------------+------+--------------------+--------------------+----------+\n",
            "|[4.3,3.0,1.1,0.1]|     0|[-9.9124117797173...|[0.72859812471276...|       0.0|\n",
            "|[4.4,3.0,1.3,0.2]|     0|[-10.731713854480...|[0.67350355476710...|       0.0|\n",
            "|[4.5,2.3,1.3,0.3]|     0|[-10.402464629198...|[0.54874547297232...|       0.0|\n",
            "|[4.8,3.4,1.9,0.2]|     0|[-12.608071888050...|[0.64384364302941...|       0.0|\n",
            "|[5.0,2.0,3.5,1.0]|     1|[-17.210413572404...|[0.07707022754093...|       1.0|\n",
            "+-----------------+------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"target\", \n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "accuracy_nb = evaluator.evaluate(predictions_nb)\n",
        "print(f\"Test Error =\", (1.0 - accuracy_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9zXX5Pn5WMU",
        "outputId": "695f8923-1902-447f-8f6f-d65ac96e9667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Градиентный бустинг"
      ],
      "metadata": {
        "id": "zKAQgU3N5-KK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Градиентный бустинг, он же Gradient Boosting, Gradient Boosted-Tree, более правильно будет назвать ансамбль деревьев решений, обученный с использованием градиентного бустинга.\n",
        "\n",
        "Градиентный бустинг представляет собой ансамбль деревьев решений. В основе данного алгоритма лежит итеративное обучение деревьев решений с целью минимизировать функцию потерь. Благодаря особенностям деревьев решений градиентный бустинг способен работать с категориальными признаками , справляться с нелинейностями.\n",
        "\n",
        "В Spark Ml градиентный бустинг поддерживает бинарную классификацию и регрессию с использованием как непрерывных признаков, так и категориальных. \n",
        "\n",
        "Gradient-Boosted Trees не поддерживает многоклассовую классификацию. Если вам она нужна, то используйте случайный лес (Random Forest)."
      ],
      "metadata": {
        "id": "Q92zA0VK5_9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В Spark Ml для градиентного бустинга предусмотрены три функции потерь: для классификации - Логистическая потеря (log loss) и для регрессии - Квадратическая ошибка и Абсолютная ошибка. "
      ],
      "metadata": {
        "id": "lhVJKdQO6Zvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.regression import GBTRegressor"
      ],
      "metadata": {
        "id": "xk2AtI_R5_fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Деревья решений"
      ],
      "metadata": {
        "id": "zHs8cMaS9erA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Деревья решений (Decision trees) являются одним из самых популярных алгоритмов машинного обучения и используются для задач классификации (бинарной и многоклассовой) и регрессии. Деревья решений простоты, понятны, они хорошо обрабатывают категориальные значения, а также могут находить нелинейные связи. "
      ],
      "metadata": {
        "id": "y1PY0emi9k3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Логистическая регрессия"
      ],
      "metadata": {
        "id": "Qaj4oTqaIHb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "V9MiX5QIIUQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol='target')"
      ],
      "metadata": {
        "id": "tpKERubhI5hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr = lr.fit(training_df)"
      ],
      "metadata": {
        "id": "0obB4QcTI_jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Coefficients: \\n\" + str(model_lr.coefficientMatrix))\n",
        "print(\"Intercept: \" + str(model_lr.interceptVector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5QeN-U_JKwa",
        "outputId": "9604e997-8400-48fa-ed96-b7c8f4a1b1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            "3 X 4 CSRMatrix\n",
            "(0,2) -0.2626\n",
            "(0,3) -0.3154\n",
            "(1,3) 0.2256\n",
            "Intercept: [0.9335770202608067,-0.2726324816200717,-0.6609445386407349]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_lr = model_lr.transform(test_df)"
      ],
      "metadata": {
        "id": "WGr62GBcJbaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"target\", \n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "accuracy_lr = evaluator.evaluate(predictions_lr)\n",
        "print(f\"Test Error =\", (1.0 - accuracy_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkRKSEcrJjJa",
        "outputId": "95c03a1e-2d17-4c19-c91c-f7216aa31f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.0\n"
          ]
        }
      ]
    }
  ]
}
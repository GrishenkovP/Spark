{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1DIktNdlDjMb"
      },
      "outputs": [],
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "!rm /content/spark-3.3.1-bin-hadoop3.tgz\n",
        "!mv /content/spark-3.3.1-bin-hadoop3 /content/apache_spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os"
      ],
      "metadata": {
        "id": "LfX1XQ5eE67H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(\"/content/apache_spark/python/lib/py4j-0.10.9.5-src.zip\")\n",
        "sys.path.append(\"/content/apache_spark/python\")\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/apache_spark\""
      ],
      "metadata": {
        "id": "vJxyYkYXExsH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType\n",
        "from pyspark.sql.functions import col,lit,array_contains\n",
        "from pyspark.sql.functions import sum,avg,max,min,mean,count\n",
        "from pyspark.sql.functions import udf"
      ],
      "metadata": {
        "id": "ipzYLpj9Gsbf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master('local[*]').enableHiveSupport().appName(\"SparkTest\").getOrCreate()"
      ],
      "metadata": {
        "id": "gkF-7VumGwi2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "schema = StructType([ \\\n",
        "    StructField(\"firstname\",StringType(),True), \\\n",
        "    StructField(\"middlename\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True), \\\n",
        "    StructField(\"id\", StringType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True), \\\n",
        "    StructField(\"salary\", IntegerType(), True) \\\n",
        "  ])\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=schema)"
      ],
      "metadata": {
        "id": "T_XUofA6ILzu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(employee_name):\n",
        "  return df.filter(df.firstname == employee_name).show(truncate=False)"
      ],
      "metadata": {
        "id": "0aGfgA37IMk-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main('Robert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfohaH7oIVc1",
        "outputId": "6c991efa-7759-4db2-be41-404627f5c60a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pyspark_job.py --employee_name='Robert'"
      ],
      "metadata": {
        "id": "zSJLNcZZIaTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!${SPARK_HOME}/bin/spark-submit pyspark_job.py --employee_name='Maria'"
      ],
      "metadata": {
        "id": "maGUjC2ELRmG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pyspark3.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1rZWiGWyUJQnOeYQkStHXlfHGPprC6mnb","authorship_tag":"ABX9TyNIg+gpi5MH/uCKm8udp+jC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"k5ETcoy84vef","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599303020646,"user_tz":-300,"elapsed":905,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}}},"source":["#импорт библиотек\n","import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dj0siI2d431L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599303036040,"user_tz":-300,"elapsed":1053,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvOqwsaI5EHS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599303134048,"user_tz":-300,"elapsed":21176,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}}},"source":["# Install the dependencies\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n","!tar xf spark-3.0.0-bin-hadoop2.7.tgz\n","!pip install -q findspark"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eizjz3Vs47gS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599303143181,"user_tz":-300,"elapsed":6481,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}}},"source":["# Run the local session to test the installation\n","import findspark\n","findspark.init('spark-3.0.0-bin-hadoop2.7')\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master('local[*]').getOrCreate()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqLjt7MA5Yrj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1599303497505,"user_tz":-300,"elapsed":1140,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}},"outputId":"c74bb63f-aa8d-4ffc-aaf8-7949a65cb8c0"},"source":["from pyspark.sql.types import *\n","\n","idColumn = StructField('id', IntegerType(),True)\n","regionColumn = StructField('region',StringType(),True)\n","managerColumn = StructField('manager',StringType(),True)\n","productColumn = StructField('product', StringType(),True)\n","amountColumn = StructField('amount', IntegerType(),True)\n","\n","columnList = [idColumn, regionColumn, managerColumn, productColumn, amountColumn]\n","\n","salesDfSchema = StructType(columnList)\n","\n","salesDf = spark.read.csv('drive/My Drive/Colab Notebooks/demo_sales.csv', schema = salesDfSchema, header = True, sep=\";\")\n","salesDf.show()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["+---+------+-------+-------+------+\n","| id|region|manager|product|amount|\n","+---+------+-------+-------+------+\n","|  1|   AAA| Ivanov|     a1|   100|\n","|  2|   BBB|Sidorov|     a1|   150|\n","|  3|   DDD| Petrov|     b2|   250|\n","|  4|   BBB|Sidorov|     a1|   350|\n","|  5|   DDD| Petrov|     b2|   250|\n","|  6|   FFF| Ivanov|     a3|   100|\n","|  7|   BBB|Sidorov|     a3|   150|\n","|  8|   DDD| Petrov|     b2|   250|\n","|  9|   BBB|Sidorov|     a1|   350|\n","| 10|   DDD| Petrov|     b2|   250|\n","+---+------+-------+-------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hKAhGH3x5qjU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1599303609155,"user_tz":-300,"elapsed":780,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}},"outputId":"2aa2123b-05af-4d08-e0c8-cddb2eb47c6a"},"source":["salesDf.createOrReplaceTempView('salesDfSQL')\n","\n","outputDf = spark.sql('select * from salesDfSQL').show()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["+---+------+-------+-------+------+\n","| id|region|manager|product|amount|\n","+---+------+-------+-------+------+\n","|  1|   AAA| Ivanov|     a1|   100|\n","|  2|   BBB|Sidorov|     a1|   150|\n","|  3|   DDD| Petrov|     b2|   250|\n","|  4|   BBB|Sidorov|     a1|   350|\n","|  5|   DDD| Petrov|     b2|   250|\n","|  6|   FFF| Ivanov|     a3|   100|\n","|  7|   BBB|Sidorov|     a3|   150|\n","|  8|   DDD| Petrov|     b2|   250|\n","|  9|   BBB|Sidorov|     a1|   350|\n","| 10|   DDD| Petrov|     b2|   250|\n","+---+------+-------+-------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kxgb5HJG7OGu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1599303680691,"user_tz":-300,"elapsed":927,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}},"outputId":"1422fb80-e8fe-4d61-c51b-ace4d6502202"},"source":["spark.sql('Describe salesDfSQL').show()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["+--------+---------+-------+\n","|col_name|data_type|comment|\n","+--------+---------+-------+\n","|      id|      int|   null|\n","|  region|   string|   null|\n","| manager|   string|   null|\n","| product|   string|   null|\n","|  amount|      int|   null|\n","+--------+---------+-------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IjLYJlen7Y-C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1599306411665,"user_tz":-300,"elapsed":1179,"user":{"displayName":"Павел Гришенков","photoUrl":"","userId":"03898497884916183776"}},"outputId":"be4cfa0e-3ca0-474a-bcac-9d44f6beee6a"},"source":["spark.sql(\"select region, manager,product, amount \\\n","            from salesDfSQL \\\n","            where product='a1'\").toPandas().head()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>manager</th>\n","      <th>product</th>\n","      <th>amount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAA</td>\n","      <td>Ivanov</td>\n","      <td>a1</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BBB</td>\n","      <td>Sidorov</td>\n","      <td>a1</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BBB</td>\n","      <td>Sidorov</td>\n","      <td>a1</td>\n","      <td>350</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BBB</td>\n","      <td>Sidorov</td>\n","      <td>a1</td>\n","      <td>350</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  region  manager product  amount\n","0    AAA   Ivanov      a1     100\n","1    BBB  Sidorov      a1     150\n","2    BBB  Sidorov      a1     350\n","3    BBB  Sidorov      a1     350"]},"metadata":{"tags":[]},"execution_count":29}]}]}
